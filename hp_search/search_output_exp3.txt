python3 main.py --train ../wbi_binary/pre2_train.csv --score --hp randomized
2017-06-23 14:56:49,474 DEBUG Commandline arguments: Namespace(hp='randomized', hp_metric='accuracy', model=None, oob=False, predict=None, score=True, test_size=0.25, train=<_io.TextIOWrapper name='../wbi_binary/pre2_train.csv' mode='r' encoding='UTF-8'>)
2017-06-23 14:56:49,474 DEBUG Valid mode of operation
2017-06-23 14:56:49,474 INFO Mode score->train
2017-06-23 14:56:49,474 DEBUG Loading data...
2017-06-23 14:56:49,563 INFO Created training set (1616) and test set (539)
2017-06-23 14:56:49,563 INFO Recognised data-set: binary
2017-06-23 14:56:49,564 INFO Using randomized search on the training set to select the best model (hyper-parameters)...
2017-06-23 14:56:49,564 DEBUG Performing randomized search, optimizing accuracy score...
Fitting 5 folds for each of 6 candidates, totalling 30 fits
[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.2min finished
Hyper parameter search report:
Parameter search space:
{'clf__criterion': ['gini'],
 'clf__n_estimators': [1000],
 'union__abstractPosTokLemSyn': ['Pipeline'],
 'union__abstractPosTokLemSyn__vectorizer__ngram_range': [(1, 1),
                                                          (2, 2),
                                                          (3, 3),
                                                          (1, 2),
                                                          (1, 3),
                                                          (2, 3)],
 'union__abstractWordCount': [None],
 'union__char_ngrams': [None],
 'union__keyword_vector': [None],
 'union__term_vector': [None],
 'union__titleWordCount': [None],
 'union__word_ngrams': [None]}
Best score: 0.922
Best parameters set:
{'clf__criterion': 'gini',
 'clf__n_estimators': 1000,
 'union__abstractPosTokLemSyn': 'Pipeline',
 'union__abstractPosTokLemSyn__vectorizer__ngram_range': (1, 3),
 'union__abstractWordCount': None,
 'union__char_ngrams': None,
 'union__keyword_vector': None,
 'union__term_vector': None,
 'union__titleWordCount': None,
 'union__word_ngrams': None}
Detailed folds results:
   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_clf__criterion param_clf__n_estimators param_union__abstractPosTokLemSyn  \
0      10.545645         0.664176         0.920792               1.0                 gini                    1000                          Pipeline   
1      30.945244         1.042240         0.907178               1.0                 gini                    1000                          Pipeline   
2      49.421634         1.121817         0.758045               1.0                 gini                    1000                          Pipeline   
3      34.461471         1.558321         0.917698               1.0                 gini                    1000                          Pipeline   
4      52.821432         2.289151         0.922030               1.0                 gini                    1000                          Pipeline   
5      48.138136         1.319087         0.889233               1.0                 gini                    1000                          Pipeline   

  param_union__abstractPosTokLemSyn__vectorizer__ngram_range param_union__abstractWordCount param_union__char_ngrams param_union__keyword_vector param_union__term_vector param_union__titleWordCount  \
0                                             (1, 1)                                   None                     None                        None                     None                        None   
1                                             (2, 2)                                   None                     None                        None                     None                        None   
2                                             (3, 3)                                   None                     None                        None                     None                        None   
3                                             (1, 2)                                   None                     None                        None                     None                        None   
4                                             (1, 3)                                   None                     None                        None                     None                        None   
5                                             (2, 3)                                   None                     None                        None                     None                        None   

  param_union__word_ngrams  rank_test_score  split0_test_score  split0_train_score  split1_test_score  split1_train_score  split2_test_score  split2_train_score  split3_test_score  \
0                     None                2           0.910494                 1.0           0.944272                 1.0           0.919505                 1.0           0.919505   
1                     None                4           0.898148                 1.0           0.934985                 1.0           0.904025                 1.0           0.907121   
2                     None                6           0.765432                 1.0           0.761610                 1.0           0.743034                 1.0           0.773994   
3                     None                3           0.895062                 1.0           0.947368                 1.0           0.916409                 1.0           0.919505   
4                     None                1           0.907407                 1.0           0.959752                 1.0           0.907121                 1.0           0.919505   
5                     None                5           0.876543                 1.0           0.922601                 1.0           0.869969                 1.0           0.897833   

   split3_train_score  split4_test_score  split4_train_score  std_fit_time  std_score_time  std_test_score  std_train_score  
0                 1.0           0.910217                 1.0      0.645797        0.092298        0.012429              0.0  
1                 1.0           0.891641                 1.0      0.646289        0.136340        0.014870              0.0  
2                 1.0           0.746130                 1.0      1.651120        0.206811        0.011736              0.0  
3                 1.0           0.910217                 1.0      2.470480        0.209072        0.017055              0.0  
4                 1.0           0.916409                 1.0      2.208166        0.233987        0.019476              0.0  
5                 1.0           0.879257                 1.0      8.428828        0.416940        0.019070              0.0  
Search results saved as search_results.csv
2017-06-23 15:03:06,109 DEBUG randomized search done in 0:06:13.217758
2017-06-23 15:03:06,229 INFO Evaluating the selected model on the test set...
2017-06-23 15:03:25,189 DEBUG Fitted 1616 data points.
2017-06-23 15:03:25,189 DEBUG Fitting done in 0:00:18.960214
Evaluation report:
             precision    recall  f1-score   support

     cancer       0.88      0.98      0.93       271
  nonCancer       0.98      0.87      0.92       268

avg / total       0.93      0.92      0.92       539

Accuracy: 0.9239332096474954
2017-06-23 15:03:26,326 DEBUG Evaluation done in 0:00:01.128427
2017-06-23 15:03:26,365 INFO Building the selected model on the whole data set...
Hyper parameters:
{'clf__bootstrap': True,
 'clf__class_weight': None,
 'clf__criterion': 'gini',
 'clf__max_depth': None,
 'clf__max_features': 'auto',
 'clf__max_leaf_nodes': None,
 'clf__min_impurity_split': 1e-07,
 'clf__min_samples_leaf': 1,
 'clf__min_samples_split': 2,
 'clf__min_weight_fraction_leaf': 0.0,
 'clf__n_estimators': 1000,
 'clf__n_jobs': -1,
 'clf__oob_score': False,
 'clf__random_state': <mtrand.RandomState object at 0x7f77761c0ab0>,
 'clf__verbose': 0,
 'clf__warm_start': False,
 'union__abstractPosTokLemSyn__selector': ItemSelector(key='Tokens'),
 'union__abstractPosTokLemSyn__selector__key': 'Tokens',
 'union__abstractPosTokLemSyn__vectorizer__analyzer': 'word',
 'union__abstractPosTokLemSyn__vectorizer__binary': False,
 'union__abstractPosTokLemSyn__vectorizer__decode_error': 'strict',
 'union__abstractPosTokLemSyn__vectorizer__dtype': <class 'numpy.int64'>,
 'union__abstractPosTokLemSyn__vectorizer__encoding': 'utf-8',
 'union__abstractPosTokLemSyn__vectorizer__input': 'content',
 'union__abstractPosTokLemSyn__vectorizer__lowercase': False,
 'union__abstractPosTokLemSyn__vectorizer__max_df': 1.0,
 'union__abstractPosTokLemSyn__vectorizer__max_features': None,
 'union__abstractPosTokLemSyn__vectorizer__min_df': 1,
 'union__abstractPosTokLemSyn__vectorizer__ngram_range': (1, 3),
 'union__abstractPosTokLemSyn__vectorizer__norm': 'l2',
 'union__abstractPosTokLemSyn__vectorizer__preprocessor': None,
 'union__abstractPosTokLemSyn__vectorizer__smooth_idf': True,
 'union__abstractPosTokLemSyn__vectorizer__stop_words': None,
 'union__abstractPosTokLemSyn__vectorizer__strip_accents': None,
 'union__abstractPosTokLemSyn__vectorizer__sublinear_tf': False,
 'union__abstractPosTokLemSyn__vectorizer__token_pattern': '(?u)\\b\\w\\w+\\b',
 'union__abstractPosTokLemSyn__vectorizer__tokenizer': <function additional_data_tokenizer at 0x7f77798fe0d0>,
 'union__abstractPosTokLemSyn__vectorizer__use_idf': True,
 'union__abstractPosTokLemSyn__vectorizer__vocabulary': None,
 'union__abstractWordCount': None,
 'union__char_ngrams': None,
 'union__keyword_vector': None,
 'union__n_jobs': 1,
 'union__term_vector': None,
 'union__titleWordCount': None,
 'union__transformer_weights': None,
 'union__word_ngrams': None}
2017-06-23 15:03:55,106 DEBUG Fitted 2155 data points.
2017-06-23 15:03:55,106 DEBUG Fitting done in 0:00:28.737741
Model saved as model_2017-06-23--15-03-26.pkl
