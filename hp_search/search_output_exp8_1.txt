python3 main.py --train ../wbi_binary/pre2_train.csv --score --hp randomized
2017-06-24 12:09:18,273 DEBUG Commandline arguments: Namespace(hp='randomized', hp_metric='accuracy', model=None, oob=False, predict=None, score=True, test_size=0.25, train=<_io.TextIOWrapper name='../wbi_binary/pre2_train.csv' mode='r' encoding='UTF-8'>)
2017-06-24 12:09:18,273 DEBUG Valid mode of operation
2017-06-24 12:09:18,273 INFO Mode score->train
2017-06-24 12:09:18,273 DEBUG Loading data...
2017-06-24 12:09:18,359 INFO Created training set (1616) and test set (539)
2017-06-24 12:09:18,359 INFO Recognised data-set: binary
2017-06-24 12:09:18,360 INFO Using randomized search on the training set to select the best model (hyper-parameters)...
2017-06-24 12:09:18,360 DEBUG Performing randomized search, optimizing accuracy score...
Fitting 5 folds for each of 8 candidates, totalling 40 fits
[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   40.9s finished
Hyper parameter search report:
Parameter search space:
{'clf__criterion': ['gini'],
 'clf__max_depth': [11],
 'clf__max_features': ['log2'],
 'clf__max_leaf_nodes': [55],
 'clf__min_impurity_split': [1e-05],
 'clf__min_samples_leaf': [2],
 'clf__min_samples_split': [3],
 'clf__min_weight_fraction_leaf': [0.0],
 'clf__n_estimators': [1000],
 'union__abstractPosTokLemSyn': [None],
 'union__abstractWordCount': [None],
 'union__char_ngrams': [None],
 'union__keyword_vector': [None],
 'union__term_vector': ['Pipeline'],
 'union__term_vector__select_chi2__k': [1000,
                                        2000,
                                        3000,
                                        4000,
                                        5000,
                                        6000,
                                        7000,
                                        7500],
 'union__titleWordCount': [None],
 'union__word_ngrams': [None]}
Best score: 0.882
Best parameters set:
{'clf__criterion': 'gini',
 'clf__max_depth': 11,
 'clf__max_features': 'log2',
 'clf__max_leaf_nodes': 55,
 'clf__min_impurity_split': 1e-05,
 'clf__min_samples_leaf': 2,
 'clf__min_samples_split': 3,
 'clf__min_weight_fraction_leaf': 0.0,
 'clf__n_estimators': 1000,
 'union__abstractPosTokLemSyn': None,
 'union__abstractWordCount': None,
 'union__char_ngrams': None,
 'union__keyword_vector': None,
 'union__term_vector': 'Pipeline',
 'union__term_vector__select_chi2__k': 4000,
 'union__titleWordCount': None,
 'union__word_ngrams': None}
Detailed folds results:
   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_clf__criterion param_clf__max_depth param_clf__max_features param_clf__max_leaf_nodes param_clf__min_impurity_split  \
0       2.663585         0.349591         0.876856          0.885830                 gini                   11                    log2                        55                         1e-05   
1       2.688326         0.331925         0.873762          0.884746                 gini                   11                    log2                        55                         1e-05   
2       2.695347         0.348398         0.876856          0.885675                 gini                   11                    log2                        55                         1e-05   
3       2.806553         0.426468         0.882426          0.888769                 gini                   11                    log2                        55                         1e-05   
4       3.085909         0.455061         0.881807          0.888769                 gini                   11                    log2                        55                         1e-05   
5       3.146140         0.470682         0.878713          0.888924                 gini                   11                    log2                        55                         1e-05   
6       3.094428         0.446708         0.875619          0.887531                 gini                   11                    log2                        55                         1e-05   
7       3.119633         0.432517         0.880569          0.888925                 gini                   11                    log2                        55                         1e-05   

  param_clf__min_samples_leaf param_clf__min_samples_split param_clf__min_weight_fraction_leaf param_clf__n_estimators param_union__abstractPosTokLemSyn param_union__abstractWordCount  \
0                           2                            3                                   0                    1000                              None                           None   
1                           2                            3                                   0                    1000                              None                           None   
2                           2                            3                                   0                    1000                              None                           None   
3                           2                            3                                   0                    1000                              None                           None   
4                           2                            3                                   0                    1000                              None                           None   
5                           2                            3                                   0                    1000                              None                           None   
6                           2                            3                                   0                    1000                              None                           None   
7                           2                            3                                   0                    1000                              None                           None   

  param_union__char_ngrams param_union__keyword_vector param_union__term_vector param_union__term_vector__select_chi2__k param_union__titleWordCount param_union__word_ngrams  rank_test_score  \
0                     None                        None                 Pipeline                                     1000                        None                     None                5   
1                     None                        None                 Pipeline                                     2000                        None                     None                8   
2                     None                        None                 Pipeline                                     3000                        None                     None                5   
3                     None                        None                 Pipeline                                     4000                        None                     None                1   
4                     None                        None                 Pipeline                                     5000                        None                     None                2   
5                     None                        None                 Pipeline                                     6000                        None                     None                4   
6                     None                        None                 Pipeline                                     7000                        None                     None                7   
7                     None                        None                 Pipeline                                     7500                        None                     None                3   

   split0_test_score  split0_train_score  split1_test_score  split1_train_score  split2_test_score  split2_train_score  split3_test_score  split3_train_score  split4_test_score  split4_train_score  \
0           0.870370            0.888545           0.885449            0.881671           0.879257            0.884764           0.866873            0.890178           0.882353            0.883991   
1           0.854938            0.883127           0.888545            0.880897           0.879257            0.885538           0.860681            0.888631           0.885449            0.885538   
2           0.861111            0.887771           0.894737            0.880124           0.885449            0.887858           0.860681            0.890178           0.882353            0.882444   
3           0.876543            0.889319           0.910217            0.887858           0.882353            0.894045           0.857585            0.887858           0.885449            0.884764   
4           0.873457            0.888545           0.904025            0.880124           0.882353            0.890951           0.854489            0.893271           0.894737            0.890951   
5           0.873457            0.893963           0.904025            0.880897           0.882353            0.890178           0.851393            0.892498           0.882353            0.887084   
6           0.858025            0.889319           0.907121            0.877030           0.869969            0.888631           0.860681            0.894045           0.882353            0.888631   
7           0.873457            0.897059           0.904025            0.875483           0.879257            0.887858           0.857585            0.893271           0.888545            0.890951   

   std_fit_time  std_score_time  std_test_score  std_train_score  
0      0.114472        0.043979        0.007092         0.003101  
1      0.073338        0.009230        0.013500         0.002599  
2      0.119943        0.039589        0.013664         0.003760  
3      0.143736        0.054517        0.016926         0.003028  
4      0.132863        0.012977        0.017184         0.004574  
5      0.167585        0.051305        0.016973         0.004638  
6      0.055417        0.014020        0.017901         0.005627  
7      0.079731        0.069458        0.015452         0.007362  
Search results saved as search_results.csv
2017-06-24 12:09:59,629 DEBUG randomized search done in 0:00:41.058236
2017-06-24 12:09:59,646 INFO Evaluating the selected model on the test set...
2017-06-24 12:10:01,259 DEBUG Fitted 1616 data points.
2017-06-24 12:10:01,259 DEBUG Fitting done in 0:00:01.612488
Evaluation report:
             precision    recall  f1-score   support

     cancer       0.91      0.79      0.84       271
  nonCancer       0.81      0.92      0.86       268

avg / total       0.86      0.85      0.85       539

Accuracy: 0.8534322820037106
2017-06-24 12:10:01,703 DEBUG Evaluation done in 0:00:00.440132
2017-06-24 12:10:01,706 INFO Building the selected model on the whole data set...
Hyper parameters:
{'clf__bootstrap': True,
 'clf__class_weight': None,
 'clf__criterion': 'gini',
 'clf__max_depth': 11,
 'clf__max_features': 'log2',
 'clf__max_leaf_nodes': 55,
 'clf__min_impurity_split': 1e-05,
 'clf__min_samples_leaf': 2,
 'clf__min_samples_split': 3,
 'clf__min_weight_fraction_leaf': 0.0,
 'clf__n_estimators': 1000,
 'clf__n_jobs': -1,
 'clf__oob_score': False,
 'clf__random_state': <mtrand.RandomState object at 0x7f9b37f67a68>,
 'clf__verbose': 0,
 'clf__warm_start': False,
 'union__abstractPosTokLemSyn': None,
 'union__abstractWordCount': None,
 'union__char_ngrams': None,
 'union__keyword_vector': None,
 'union__n_jobs': 1,
 'union__term_vector__select_chi2': SelectKBest(k=4000, score_func=<function chi2 at 0x7f9b41028048>),
 'union__term_vector__select_chi2__k': 4000,
 'union__term_vector__select_chi2__score_func': <function chi2 at 0x7f9b41028048>,
 'union__term_vector__selector': ItemSelector(key='Terms'),
 'union__term_vector__selector__key': 'Terms',
 'union__term_vector__vectorizer__analyzer': 'word',
 'union__term_vector__vectorizer__binary': False,
 'union__term_vector__vectorizer__decode_error': 'strict',
 'union__term_vector__vectorizer__dtype': <class 'numpy.int64'>,
 'union__term_vector__vectorizer__encoding': 'utf-8',
 'union__term_vector__vectorizer__input': 'content',
 'union__term_vector__vectorizer__lowercase': False,
 'union__term_vector__vectorizer__max_df': 1.0,
 'union__term_vector__vectorizer__max_features': None,
 'union__term_vector__vectorizer__min_df': 1,
 'union__term_vector__vectorizer__ngram_range': (1, 2),
 'union__term_vector__vectorizer__norm': 'l2',
 'union__term_vector__vectorizer__preprocessor': None,
 'union__term_vector__vectorizer__smooth_idf': True,
 'union__term_vector__vectorizer__stop_words': None,
 'union__term_vector__vectorizer__strip_accents': None,
 'union__term_vector__vectorizer__sublinear_tf': False,
 'union__term_vector__vectorizer__token_pattern': '(?u)\\b\\w\\w+\\b',
 'union__term_vector__vectorizer__tokenizer': <function additional_data_tokenizer at 0x7f9b39ff40d0>,
 'union__term_vector__vectorizer__use_idf': True,
 'union__term_vector__vectorizer__vocabulary': None,
 'union__titleWordCount': None,
 'union__transformer_weights': None,
 'union__word_ngrams': None}
2017-06-24 12:10:03,214 DEBUG Fitted 2155 data points.
2017-06-24 12:10:03,214 DEBUG Fitting done in 0:00:01.505071
Model saved as model_2017-06-24--12-10-01.pkl
