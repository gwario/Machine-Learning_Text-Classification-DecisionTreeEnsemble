python3 main.py --train ../wbi_binary/pre2_train.csv --score --hp randomized
2017-06-24 14:57:46,085 DEBUG Commandline arguments: Namespace(hp='randomized', hp_metric='accuracy', model=None, oob=False, predict=None, score=True, test_size=0.25, train=<_io.TextIOWrapper name='../wbi_binary/pre2_train.csv' mode='r' encoding='UTF-8'>)
2017-06-24 14:57:46,085 DEBUG Valid mode of operation
2017-06-24 14:57:46,085 INFO Mode score->train
2017-06-24 14:57:46,085 DEBUG Loading data...
2017-06-24 14:57:46,169 INFO Created training set (1616) and test set (539)
2017-06-24 14:57:46,170 INFO Recognised data-set: binary
2017-06-24 14:57:46,171 INFO Using randomized search on the training set to select the best model (hyper-parameters)...
2017-06-24 14:57:46,171 DEBUG Performing randomized search, optimizing accuracy score...
Fitting 5 folds for each of 21 candidates, totalling 105 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   44.4s
[Parallel(n_jobs=-1)]: Done 105 out of 105 | elapsed:  2.0min finished
Hyper parameter search report:
Parameter search space:
{'clf__criterion': ['gini'],
 'clf__max_depth': [11],
 'clf__max_features': ['log2'],
 'clf__max_leaf_nodes': [55],
 'clf__min_impurity_split': [1e-05],
 'clf__min_samples_leaf': [2],
 'clf__min_samples_split': [3],
 'clf__min_weight_fraction_leaf': [0.0],
 'clf__n_estimators': [1000],
 'union__abstractPosTokLemSyn': [None],
 'union__abstractWordCount': [None],
 'union__char_ngrams': [None],
 'union__keyword_vector': [None],
 'union__term_vector': ['Pipeline'],
 'union__term_vector__select_chi2__k': [1440,
                                        1450,
                                        1460,
                                        1470,
                                        1480,
                                        1490,
                                        1500,
                                        1510,
                                        1520,
                                        1530,
                                        1540,
                                        1550,
                                        1560,
                                        1570,
                                        1580,
                                        1590,
                                        1600,
                                        1610,
                                        1620,
                                        1630,
                                        1640],
 'union__titleWordCount': [None],
 'union__word_ngrams': [None]}
Best score: 0.874
Best parameters set:
{'clf__criterion': 'gini',
 'clf__max_depth': 11,
 'clf__max_features': 'log2',
 'clf__max_leaf_nodes': 55,
 'clf__min_impurity_split': 1e-05,
 'clf__min_samples_leaf': 2,
 'clf__min_samples_split': 3,
 'clf__min_weight_fraction_leaf': 0.0,
 'clf__n_estimators': 1000,
 'union__abstractPosTokLemSyn': None,
 'union__abstractWordCount': None,
 'union__char_ngrams': None,
 'union__keyword_vector': None,
 'union__term_vector': 'Pipeline',
 'union__term_vector__select_chi2__k': 1590,
 'union__titleWordCount': None,
 'union__word_ngrams': None}
Detailed folds results:
    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_clf__criterion param_clf__max_depth param_clf__max_features param_clf__max_leaf_nodes param_clf__min_impurity_split  \
0        2.662433         0.420054         0.870050          0.886139                 gini                   11                    log2                        55                         1e-05   
1        3.038395         0.420267         0.870668          0.886139                 gini                   11                    log2                        55                         1e-05   
2        3.103109         0.431009         0.867574          0.886139                 gini                   11                    log2                        55                         1e-05   
3        3.087006         0.430233         0.869431          0.886449                 gini                   11                    log2                        55                         1e-05   
4        3.041258         0.436142         0.870050          0.887686                 gini                   11                    log2                        55                         1e-05   
5        3.080344         0.434448         0.868812          0.886293                 gini                   11                    log2                        55                         1e-05   
6        3.025186         0.436911         0.869431          0.886293                 gini                   11                    log2                        55                         1e-05   
7        3.128116         0.428940         0.872525          0.887686                 gini                   11                    log2                        55                         1e-05   
8        3.114418         0.431205         0.871287          0.887995                 gini                   11                    log2                        55                         1e-05   
9        3.105866         0.436313         0.868193          0.887378                 gini                   11                    log2                        55                         1e-05   
10       3.141033         0.434785         0.869431          0.886448                 gini                   11                    log2                        55                         1e-05   
11       3.423226         0.466958         0.868812          0.885984                 gini                   11                    log2                        55                         1e-05   
12       3.580942         0.455816         0.870050          0.886757                 gini                   11                    log2                        55                         1e-05   
13       3.748027         0.486337         0.869431          0.885984                 gini                   11                    log2                        55                         1e-05   
14       4.328342         0.486779         0.871906          0.887532                 gini                   11                    log2                        55                         1e-05   
15       3.733735         0.538672         0.874381          0.888460                 gini                   11                    log2                        55                         1e-05   
16       3.867846         0.484383         0.873144          0.885984                 gini                   11                    log2                        55                         1e-05   
17       3.814411         0.462497         0.870668          0.885830                 gini                   11                    log2                        55                         1e-05   
18       3.761761         0.504767         0.868193          0.886139                 gini                   11                    log2                        55                         1e-05   
19       3.948433         0.468336         0.870668          0.887068                 gini                   11                    log2                        55                         1e-05   
20       3.318388         0.385682         0.872525          0.885211                 gini                   11                    log2                        55                         1e-05   

   param_clf__min_samples_leaf param_clf__min_samples_split param_clf__min_weight_fraction_leaf param_clf__n_estimators param_union__abstractPosTokLemSyn param_union__abstractWordCount  \
0                            2                            3                                   0                    1000                              None                           None   
1                            2                            3                                   0                    1000                              None                           None   
2                            2                            3                                   0                    1000                              None                           None   
3                            2                            3                                   0                    1000                              None                           None   
4                            2                            3                                   0                    1000                              None                           None   
5                            2                            3                                   0                    1000                              None                           None   
6                            2                            3                                   0                    1000                              None                           None   
7                            2                            3                                   0                    1000                              None                           None   
8                            2                            3                                   0                    1000                              None                           None   
9                            2                            3                                   0                    1000                              None                           None   
10                           2                            3                                   0                    1000                              None                           None   
11                           2                            3                                   0                    1000                              None                           None   
12                           2                            3                                   0                    1000                              None                           None   
13                           2                            3                                   0                    1000                              None                           None   
14                           2                            3                                   0                    1000                              None                           None   
15                           2                            3                                   0                    1000                              None                           None   
16                           2                            3                                   0                    1000                              None                           None   
17                           2                            3                                   0                    1000                              None                           None   
18                           2                            3                                   0                    1000                              None                           None   
19                           2                            3                                   0                    1000                              None                           None   
20                           2                            3                                   0                    1000                              None                           None   

   param_union__char_ngrams param_union__keyword_vector param_union__term_vector param_union__term_vector__select_chi2__k param_union__titleWordCount param_union__word_ngrams  rank_test_score  \
0                      None                        None                 Pipeline                                     1440                        None                     None               10   
1                      None                        None                 Pipeline                                     1450                        None                     None                7   
2                      None                        None                 Pipeline                                     1460                        None                     None               21   
3                      None                        None                 Pipeline                                     1470                        None                     None               13   
4                      None                        None                 Pipeline                                     1480                        None                     None               10   
5                      None                        None                 Pipeline                                     1490                        None                     None               17   
6                      None                        None                 Pipeline                                     1500                        None                     None               13   
7                      None                        None                 Pipeline                                     1510                        None                     None                3   
8                      None                        None                 Pipeline                                     1520                        None                     None                6   
9                      None                        None                 Pipeline                                     1530                        None                     None               19   
10                     None                        None                 Pipeline                                     1540                        None                     None               13   
11                     None                        None                 Pipeline                                     1550                        None                     None               17   
12                     None                        None                 Pipeline                                     1560                        None                     None               10   
13                     None                        None                 Pipeline                                     1570                        None                     None               13   
14                     None                        None                 Pipeline                                     1580                        None                     None                5   
15                     None                        None                 Pipeline                                     1590                        None                     None                1   
16                     None                        None                 Pipeline                                     1600                        None                     None                2   
17                     None                        None                 Pipeline                                     1610                        None                     None                7   
18                     None                        None                 Pipeline                                     1620                        None                     None               19   
19                     None                        None                 Pipeline                                     1630                        None                     None                7   
20                     None                        None                 Pipeline                                     1640                        None                     None                3   

    split0_test_score  split0_train_score  split1_test_score  split1_train_score  split2_test_score  split2_train_score  split3_test_score  split3_train_score  split4_test_score  split4_train_score  \
0            0.867284            0.889319           0.876161            0.880897           0.876161            0.887858           0.857585            0.885538           0.873065            0.887084   
1            0.864198            0.887771           0.876161            0.882444           0.879257            0.888631           0.854489            0.885538           0.879257            0.886311   
2            0.867284            0.889319           0.869969            0.880124           0.873065            0.886311           0.857585            0.886311           0.869969            0.888631   
3            0.864198            0.891641           0.873065            0.880124           0.873065            0.887084           0.860681            0.888631           0.876161            0.884764   
4            0.864198            0.890867           0.876161            0.883217           0.879257            0.890951           0.857585            0.887084           0.873065            0.886311   
5            0.858025            0.884675           0.885449            0.886311           0.876161            0.887858           0.851393            0.884764           0.873065            0.887858   
6            0.861111            0.885449           0.873065            0.880897           0.876161            0.891725           0.866873            0.891725           0.869969            0.881671   
7            0.867284            0.893189           0.876161            0.881671           0.873065            0.885538           0.866873            0.887858           0.879257            0.890178   
8            0.861111            0.890093           0.882353            0.887084           0.876161            0.886311           0.863777            0.887858           0.873065            0.888631   
9            0.867284            0.897833           0.873065            0.880124           0.876161            0.890178           0.854489            0.885538           0.869969            0.883217   
10           0.858025            0.883901           0.873065            0.880897           0.879257            0.892498           0.860681            0.888631           0.876161            0.886311   
11           0.861111            0.885449           0.869969            0.880897           0.873065            0.884764           0.863777            0.891725           0.876161            0.887084   
12           0.858025            0.883127           0.876161            0.881671           0.879257            0.890178           0.860681            0.887084           0.876161            0.891725   
13           0.861111            0.886997           0.876161            0.882444           0.873065            0.884764           0.863777            0.890178           0.873065            0.885538   
14           0.867284            0.891641           0.873065            0.882444           0.879257            0.889404           0.866873            0.887858           0.873065            0.886311   
15           0.867284            0.897059           0.900929            0.887858           0.873065            0.886311           0.854489            0.886311           0.876161            0.884764   
16           0.870370            0.888545           0.876161            0.882444           0.882353            0.889404           0.860681            0.882444           0.876161            0.887084   
17           0.867284            0.888545           0.869969            0.880124           0.873065            0.889404           0.869969            0.886311           0.873065            0.884764   
18           0.858025            0.888545           0.869969            0.883991           0.879257            0.891725           0.860681            0.883217           0.873065            0.883217   
19           0.864198            0.893963           0.888545            0.885538           0.873065            0.885538           0.851393            0.880897           0.876161            0.889404   
20           0.870370            0.887771           0.876161            0.880124           0.879257            0.886311           0.860681            0.885538           0.876161            0.886311   

    std_fit_time  std_score_time  std_test_score  std_train_score  
0       0.151820        0.004145        0.007024         0.002891  
1       0.110867        0.001231        0.009810         0.002141  
2       0.182226        0.010076        0.005318         0.003242  
3       0.175864        0.011060        0.005927         0.003872  
4       0.149882        0.008224        0.008009         0.002933  
5       0.075776        0.007973        0.012398         0.001404  
6       0.065660        0.007830        0.005190         0.004695  
7       0.159787        0.009313        0.004863         0.003932  
8       0.063907        0.005309        0.007867         0.001303  
9       0.030628        0.005921        0.007468         0.006172  
10      0.076076        0.004294        0.008508         0.003967  
11      0.248280        0.016879        0.005624         0.003516  
12      0.427864        0.039734        0.008855         0.003887  
13      0.422233        0.031606        0.005882         0.002563  
14      0.463638        0.038412        0.004548         0.003094  
15      0.337317        0.051606        0.015200         0.004409  
16      0.269971        0.045946        0.007292         0.002984  
17      0.384783        0.056536        0.002188         0.003289  
18      0.309862        0.061809        0.007865         0.003426  
19      0.395383        0.022718        0.012398         0.004376  
20      0.547095        0.064304        0.006581         0.002644  
Search results saved as search_results.csv
2017-06-24 14:59:45,691 DEBUG randomized search done in 0:01:59.371638
2017-06-24 14:59:45,703 INFO Evaluating the selected model on the test set...
2017-06-24 14:59:47,269 DEBUG Fitted 1616 data points.
2017-06-24 14:59:47,269 DEBUG Fitting done in 0:00:01.565273
Evaluation report:
             precision    recall  f1-score   support

     cancer       0.89      0.81      0.85       271
  nonCancer       0.82      0.90      0.86       268

avg / total       0.86      0.85      0.85       539

Accuracy: 0.8534322820037106
2017-06-24 14:59:47,690 DEBUG Evaluation done in 0:00:00.417377
2017-06-24 14:59:47,693 INFO Building the selected model on the whole data set...
Hyper parameters:
{'clf__bootstrap': True,
 'clf__class_weight': None,
 'clf__criterion': 'gini',
 'clf__max_depth': 11,
 'clf__max_features': 'log2',
 'clf__max_leaf_nodes': 55,
 'clf__min_impurity_split': 1e-05,
 'clf__min_samples_leaf': 2,
 'clf__min_samples_split': 3,
 'clf__min_weight_fraction_leaf': 0.0,
 'clf__n_estimators': 1000,
 'clf__n_jobs': -1,
 'clf__oob_score': False,
 'clf__random_state': <mtrand.RandomState object at 0x7f96a3d3eb40>,
 'clf__verbose': 0,
 'clf__warm_start': False,
 'union__abstractPosTokLemSyn': None,
 'union__abstractWordCount': None,
 'union__char_ngrams': None,
 'union__keyword_vector': None,
 'union__n_jobs': 1,
 'union__term_vector__select_chi2': SelectKBest(k=1590, score_func=<function chi2 at 0x7f96accb9048>),
 'union__term_vector__select_chi2__k': 1590,
 'union__term_vector__select_chi2__score_func': <function chi2 at 0x7f96accb9048>,
 'union__term_vector__selector': ItemSelector(key='Terms'),
 'union__term_vector__selector__key': 'Terms',
 'union__term_vector__vectorizer__analyzer': 'word',
 'union__term_vector__vectorizer__binary': False,
 'union__term_vector__vectorizer__decode_error': 'strict',
 'union__term_vector__vectorizer__dtype': <class 'numpy.int64'>,
 'union__term_vector__vectorizer__encoding': 'utf-8',
 'union__term_vector__vectorizer__input': 'content',
 'union__term_vector__vectorizer__lowercase': False,
 'union__term_vector__vectorizer__max_df': 1.0,
 'union__term_vector__vectorizer__max_features': None,
 'union__term_vector__vectorizer__min_df': 1,
 'union__term_vector__vectorizer__ngram_range': (1, 1),
 'union__term_vector__vectorizer__norm': 'l2',
 'union__term_vector__vectorizer__preprocessor': None,
 'union__term_vector__vectorizer__smooth_idf': True,
 'union__term_vector__vectorizer__stop_words': None,
 'union__term_vector__vectorizer__strip_accents': None,
 'union__term_vector__vectorizer__sublinear_tf': False,
 'union__term_vector__vectorizer__token_pattern': '(?u)\\b\\w\\w+\\b',
 'union__term_vector__vectorizer__tokenizer': <function additional_data_tokenizer at 0x7f96a5c820d0>,
 'union__term_vector__vectorizer__use_idf': True,
 'union__term_vector__vectorizer__vocabulary': None,
 'union__titleWordCount': None,
 'union__transformer_weights': None,
 'union__word_ngrams': None}
2017-06-24 14:59:49,150 DEBUG Fitted 2155 data points.
2017-06-24 14:59:49,150 DEBUG Fitting done in 0:00:01.454681
Model saved as model_2017-06-24--14-59-47.pkl

